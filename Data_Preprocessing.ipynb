{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Load Data\n",
                "Load the cleaned dataset from the previous step. \n",
                "This dataset already contains the imputed values and the 'target' binary column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv(\"processed_data/heart_disease_cleaned.csv\")\n",
                "\n",
                "# Ensure 'target' column exists, if not recreate it from 'num'\n",
                "if 'target' not in df.columns:\n",
                "    df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
                "\n",
                "# Drop the original 'num' column as we are doing binary classification\n",
                "if 'num' in df.columns:\n",
                "    df = df.drop('num', axis=1)\n",
                "\n",
                "# Check data\n",
                "print(\"Shape:\", df.shape)\n",
                "print(\"Columns:\", df.columns.tolist())\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Encoding Categorical Variables\n",
                "Use One-Hot Encoding for categorical variables with more than two levels:\n",
                "- cp (Chest Pain Type)\n",
                "- restecg (Resting ECG)\n",
                "- slope (Slope of peak exercise ST segment)\n",
                "- thal (Thalassemia)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define categorical columns\n",
                "categorical_cols = ['cp', 'restecg', 'slope', 'thal']\n",
                "\n",
                "# Apply One-Hot Encoding using pandas get_dummies\n",
                "# drop_first=True helps avoid multicollinearity (dummy variable trap)\n",
                "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
                "\n",
                "print(\"Encoded Shape:\", df_encoded.shape)\n",
                "df_encoded.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Splitting the Data\n",
                "Perform an 80/20 Train-Test split. Use a random_state for reproducibility."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Features (X) and Target (y)\n",
                "X = df_encoded.drop('target', axis=1)\n",
                "y = df_encoded['target']\n",
                "\n",
                "# Split the data\n",
                "# random_state=42 is a common convention for reproducibility\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "print(f\"Training Shape: {X_train.shape}\")\n",
                "print(f\"Testing Shape: {X_test.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Feature Scaling\n",
                "Apply StandardScaler to numerical features. \n",
                "Crucial step: We fit the scaler ONLY on the training data, then transform both training and testing data.\n",
                "This prevents 'Data Leakage' (peeking at the test set)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define numerical columns that need scaling\n",
                "# Note: 'sex', 'fbs', 'exang', 'ca' are essentially categorical/ordinal or binary.\n",
                "# We will scale the continuous variables: Age, Trestbps, Chol, Thalach, Oldpeak\n",
                "numeric_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
                "\n",
                "scaler = StandardScaler()\n",
                "\n",
                "# Fit on Training Data ONLY\n",
                "scaler.fit(X_train[numeric_cols])\n",
                "\n",
                "# Transform Training and Testing Data\n",
                "X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\n",
                "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
                "\n",
                "print(\"Scaling done.\")\n",
                "X_train.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. Save Processed Data\n",
                "Save the processed training and testing sets separately to preserve the split and scaling."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Recombine X and y for saving (optional, but convenient)\n",
                "train_data = X_train.copy()\n",
                "train_data['target'] = y_train\n",
                "\n",
                "test_data = X_test.copy()\n",
                "test_data['target'] = y_test\n",
                "\n",
                "# Save to CSV\n",
                "train_data.to_csv(\"processed_data/train_processed.csv\", index=False)\n",
                "test_data.to_csv(\"processed_data/test_processed.csv\", index=False)\n",
                "\n",
                "print(\"Processed files saved:\")\n",
                "print(\"- processed_data/train_processed.csv\")\n",
                "print(\"- processed_data/test_processed.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}